library("ggplot2", lib.loc="~/R/win-library/3.3")
detach("package:ggplot2", unload=TRUE)
install.packages(c("colorspace", "curl", "evaluate", "ggplot2", "htmlwidgets", "knitr", "openssl", "R6", "reshape2", "rmarkdown", "scales", "shiny", "stringi", "XML"))
```{r}
class(sin)
class(sample)
resample = function(x) {
return(sample(x, size=length(x), replace=TRUE))
}
class(resample)
# Facts About Functions
body(resample)
args(resample)
environment(resample)
# The grad() function
library(numDeriv)
args(grad)
simpleFun = function(x) {
# x is a vector of length 2
return(x[1]^2 + 1/3*x[2]^2)
}
xpt <- runif(n = 2, min = -2, max = 2)
grad(simpleFun, xpt)
c(2*xpt[1], 2/3*xpt[2])
## Section II: Basic Optimization ##
grad.descent <- function(f, x0, max.iter = 200, step.size = 0.05, stopping.deriv = 0.01, ...) {
n    <- length(x0)
xmat <- matrix(0, nrow = n, ncol = max.iter)
xmat[,1] <- x0
for (k in 2:max.iter) {
# Calculate the gradient
grad.cur <- grad(f, xmat[ ,k-1], ...)
# Should we stop?
if (all(abs(grad.cur) < stopping.deriv)) {
k <- k-1; break
}
# Move in the opposite direction of the grad
xmat[ ,k] <- xmat[ ,k-1] - step.size * grad.cur
}
xmat <- xmat[ ,1:k] # Trim
return(list(x = xmat[,k], xmat = xmat, k = k))
}
x0 <- c(-1.9, -1.9)
gd <- grad.descent(simpleFun, x0)
gd$x
gd$k
?nlm
factory.n <- list(c("labor","steel"), c("car","truck"))
factory   <- matrix(c(40, 1, 60, 3), nrow = 2, dimnames = factory.n)
View(factory)
a <- matrix(c(1,2,3,4), nrwo=2)
a <- matrix(c(1,2,3,4), nrow =2)
View(a)
n <- 100
p <- 10
s <- 3
set.seed(0)
x <- matrix(rnorm(n*p), n, p)
b <- c(-0.7, 0.7, 1, rep(0, p-s))
y <- x %*% b + rt(n, df=2)
lm(y~., data = x)
x <- as.data.frame(x)
lm(y~., data = x)
View(x)
plot(z, dnorm(z), col = "red")
z <- seq(-5, 5, by = 0.01)
plot(z, dnorm(z), col = "red")
plot(z, dt(z,df = 3), col = "blue", add = TRUE)
plot(z, dnorm(z), col = "red")
plot(z, dt(z,df = 3), col = "blue")
plot(z, dnorm(z), col = "red", cex = 0.2)
library(ggplot2)
curve(dnrom, -8, -8)
curve(dnrom(z), -8, -8)
curve(dnrom(x), -8, -8)
ggplot+geom_line(mappping = aes(z, dnorm(z)))
ggplot+geom_line(mappping = aes(x= z, y=dnorm(z)))
ggplot(mappping = aes(x= z, y=dnorm(z)))
geom_line(mappping = aes(x= z, y=dnorm(z)))
geom_line(mapping = aes(x= z, y=dnorm(z)))
ggplot+geom_line(mapping = aes(x= z, y=dnorm(z)))
ggplot(data=z)+geom_line(mapping = aes(x= z, y=dnorm(z)))
ggplot+geom_points(mapping = aes(x= z, y=dnorm(z)))
ggplot+geom_point(mapping = aes(x= z, y=dnorm(z)))
geom_point(mapping = aes(x= z, y=dnorm(z)))
ggplot(mapping = aes(x= z, y=dnorm(z)))
ggplot(aes(x= z, y=dnorm(z)))
ggplot(mpg, aes(x= z, y=dnorm(z)))
```{r}
z <- seq(-8, 8, by = 0.01)
plot(z, dnorm(z), col = "red", cex = 0.2)
plot(z, dt(z,df = 3), col = "blue", cex = 0.2)
plot(z, dnorm(z), col = "red", cex = 0.2)
plot(z, dt(z,df = 3), col = "blue", cex = 0.2)
curve(dnrom(x))
curve(dnorm(x))
curve(dnorm(x),-5,5,add = TRUE)
?curve
plot(z, dnorm(z), col = "red", cex = 0.2)
plot(z, dt(z,df = 3), col = "blue", cex = 0.2)
curve(dnorm(x),from = -5, to = 5,add = TRUE)
z <- seq(-5, 5, by = 0.01)
curve(dnorm(x),from = -5, to = 5,add = TRUE, col= "red", cex = 0.2)
z <- seq(-5, 5, by = 0.01)
plot(z, dt(z,df = 3), col = "blue", cex = 0.2)
curve(dnorm(x),from = -5, to = 5,add = TRUE, col= "red", cex = 0.2)
plot(z, dt(z,df = 3), col = "blue", cex = 0.1)
curve(dnorm(x),from = -5, to = 5,add = TRUE, col= "red", cex = 0.2)
plot(z, dt(z,df = 3), col = "blue", cex = 0.01)
curve(dnorm(x),from = -5, to = 5,add = TRUE, col= "red", cex = 0.2)
?curve
z <- seq(-5, 5, by = 0.01)
plot(z, dt(z,df = 3), col = "blue", cex = 0.01, xlab = "x", ylab = "pdf(x)")
curve(dnorm(x),from = -5, to = 5,add = TRUE, col= "red", cex = 0.2)
?plot
legend("bottomright", legend = c("Normal", "T"), fill =c("red", "blue"))
legend("upright", legend = c("Normal", "T"), fill =c("red", "blue"))
legend("topright", legend = c("Normal", "T"), fill =c("red", "blue"))
z <- seq(-5, 5, by = 0.01)
plot(z, dt(z,df = 3), col = "blue", cex = 0.01, xlab = "x", ylab = "pdf(x)")
curve(dnorm(x),from = -5, to = 5,add = TRUE, col= "red", cex = 0.2)
legend("topright", legend = c("Normal", "T"), fill =c("red", "blue"))
z <- seq(-5, 5, by = 0.01)
plot(z, dt(z,df = 3), col = "blue", cex = 0.01, xlab = "x", ylab = "pdf(x)")
curve(dnorm(x),from = -5, to = 5,add = TRUE, col= "red", cex = 0.2)
legend("topright", legend = c("Normal", "Student T"), fill =c("red", "blue"))
psi <- function(r, c = 1) {
return(ifelse(r^2 > c^2, 2*c*abs(r) - c^2, r^2))
}
huber.loss <- function(beta){
loss <- y-x%*%beta
return(sum(psi(loss)))
}
q <- rep(1,10)
huber.loss(q)
q <- c(rep(1,10))
q
huber.loss(q)
huber.loss(q)
huber.loss <- function(beta){
return(x)
loss <- (y-x%*%beta)
return(sum(psi(loss)))
}
huber.loss(q)
q <- as.matrix(q)
q
huber.loss <- function(beta){
beta <- as.matrix(beta)
loss <- (y-x%*%beta)
return(sum(psi(loss)))
}
huber.loss(q)
x%*%q
b
q
q <- c(1,1,1,1,1,1,1,1,1,1)
q
b
q <- as.numeric(q)
q
huber.loss(q)
x%*%q
mode(b)
mode(q)
typeof(b)
typeof(q)
x%*%b
n <- 100
p <- 10
s <- 3
set.seed(0)
x <- matrix(rnorm(n*p), n, p)
b <- c(-0.7, 0.7, 1, rep(0, p-s))
y <- x %*% b + rt(n, df=2)
x <- as.data.frame(x)
lm(y~., data = x)
x %*% b
beta <- q
loss <- (y-x%*%beta)
n <- 100
p <- 10
s <- 3
set.seed(0)
x <- matrix(rnorm(n*p), n, p)
b <- c(-0.7, 0.7, 1, rep(0, p-s))
y <- x %*% b + rt(n, df=2)
x %*% b
huber.loss <- function(beta){
loss <- (y - x %*% beta)
return(sum(psi(loss)))
}
huber.loss(q)
gd <- grad.descent(huber.loss, rep(0,p))
grad.descent <- function(f, x0, max.iter = 200, step.size = 0.001, stopping.deriv = 0.1, ...) {
n    <- length(x0)
xmat <- matrix(0, nrow = n, ncol = max.iter)
xmat[,1] <- x0
for (k in 2:max.iter) {
# Calculate the gradient
grad.cur <- grad(f, xmat[ ,k-1], ...)
# Should we stop?
if (all(abs(grad.cur) < stopping.deriv)) {
k <- k-1; break
}
# Move in the opposite direction of the grad
xmat[ ,k] <- xmat[ ,k-1] - step.size * grad.cur
}
xmat <- xmat[ ,1:k] # Trim
return(list(x = xmat[,k], xmat = xmat, k = k))
}
gd <- grad.descent(huber.loss, rep(0,p))
library(numDeriv)
grad.descent <- function(f, x0, max.iter = 200, step.size = 0.001, stopping.deriv = 0.1, ...) {
n    <- length(x0)
xmat <- matrix(0, nrow = n, ncol = max.iter)
xmat[,1] <- x0
for (k in 2:max.iter) {
# Calculate the gradient
grad.cur <- grad(f, xmat[ ,k-1], ...)
# Should we stop?
if (all(abs(grad.cur) < stopping.deriv)) {
k <- k-1; break
}
# Move in the opposite direction of the grad
xmat[ ,k] <- xmat[ ,k-1] - step.size * grad.cur
}
xmat <- xmat[ ,1:k] # Trim
return(list(x = xmat[,k], xmat = xmat, k = k))
}
gd <- grad.descent(huber.loss, rep(0,p))
gd
gd$x
choose(100,6)*(0.08)^6*(0.92)*94
choose(100,6)*(0.08)^6*(0.92)^94
1-choose(100,6)*(0.04)^6*(0.96)^94
a <- 75/300
b <- 1.65*sqrt(a*(1-a)/300)
a+b
a-b
0.95^0.25
pnorm(0)
pnorm(0.01)-0.5
m <- 1- 1.645/4
1-pnorm(m)
m*4
m <- m*4
1-pnorm(m)
s <- -11.981/2/sqrt(2)
1-pnorm(z)
1-pnorm(s)
2*sqrt(2)*1.645-8
quantile(1)
qnorm(0.99)
qchisq(0.01, 1)
qnorm(0.5)
qnorm(0.6)
qchisq(0.99, 1)
x <- c("d", "c", "d")
y <- c(1,2,2)
z <- data.frame(X=x, Y=y)
table(z$X,z$Y)
s <- split(z, y)
s
x <- rnorm(100, 0 ,1)
qqplot(x, qnorm(c(1:100),0,1))
x <- rnorm(100, 0 ,1)
qqplot(x, qnorm(c(1:100)/100,0,1))
abline(0,1,col= "red")
plot(ecdf(pnorm(x,0,1)))
x <- rnorm(10000, 0 ,1)
qqplot(x, qnorm(c(1:100)/100,0,1))
abline(0,1,col= "red")
plot(ecdf(pnorm(x,0,1)))
abline(0,1,col= "red")
quantile(x,0.5)
quantile(x,1)
max(x)
plot(quantile(x,c(1:100)/100), qnorm(c(1:100)/100,0,1))
?nls
a <- matrix(c(1:32),2,4,4)
a
a[3]
a[2,3]
a[1,1,4]
a <- array(c(1:32),dim = c(4,2,4))
a
a[2]
a[[4]]
a[[14]]
a[4,1,1]
a[1,1,4]
a[1,2,4]
library(plry)
library(plyr)
a_ply(a, 3, plot)
a_ply(a, 2:3, plot)
x <- rnorm(100, 0,2)
y <- rgamma(100, 1,1 )
z <- 3*x
q<- cbind(x,y,z)
dim(q)
prcomp(q)
summary(prcomp(q))
library(tm)
library(wordcloud)
library(RColorBrewer)
library(dplyr)
library(tidytext)
library(ggplot2)
install.packages(tm)
install.packages("tm")
library(tm)
library(tm)
install.packages("wordcloud")
install.packages("dplyr")
install.packages("tidytext")
install.packages("RColorBrewer")
install.packages("RColorBrewer")
library(tm)
library(wordcloud)
library(RColorBrewer)
install.packages(e1071)
install.packages("e1071")
install.packages("rgooglemap")
install.packages(shiny)
install.packages("shiny")
require(ggmap)
a <- geocode("3698 SACRAMENTO STREET", output = "more")
a
a$postal_code
a <- geocode("Child Health Center Queens", output = "more")
a$postal_code
a <- geocode("(41.720959999999998, -87.621351000000004)", output = "more")
a$lon
a$lat
require(ggamp)
require(ggmap)
a <- geocode("Palega ball fields 94134", output = "more")
a
pchisq(20,1)
a <- 0.00140
b <- 0.00010
a*(1-b)/(b*(1-a))
1493*557/1198/1278
1/0.5431594
a <- 854/1103
n <- 1103
b <- 0.75
n*(a-b)^2/a/(1-a)
pchisq(3.711, 1)
0.096/(1-0.096)
0.847/(1-0.847)
0.906/(1-0.096)
0.906/(1-0.906)
5.535/9.638
odd <- function(a,b){}
odd <- function(a,b){
return(a*(1-b)/b/(1-a))
}
odd(0.0263,0.0049)
odd(0.0072,0.0023)
1/odd(0.0263,0.0049)
1/odd(0.0072,0.0023)
1/odd(0.0335,0.0072)
57*0.12
391*0.08
source("http://bioconductor.org/biocLite.R")
biocLite()
a <- seq(0, 1, length.out=10)
a
a <- seq(0, 1, length.out=11)
a
c <- rep(1,10)
c
c <- rep(1:5,10)
c
X <- read.csv(choose.files())
X <- t(X)
labels <- read.csv(choose.files())
r <- sample(1:2000, 2000)
r <- r[1:1000]
dat_train<-X[r,]
label_train <- labels[r,1]
data.all <- as.data.frame(cbind(dat_train, label_train))
colnames(data.all)[ncol(data.all)] <- "Label"
data.all$Label <- as.factor(data.all$Label)
control <- trainControl(method = 'cv', number = 5)  #use 5-fold cross validation
inTrain <- createDataPartition(y = data.all$Label, p=0.75, list=FALSE)
library("caret")
data.all <- as.data.frame(cbind(dat_train, label_train))
colnames(data.all)[ncol(data.all)] <- "Label"
data.all$Label <- as.factor(data.all$Label)
control <- trainControl(method = 'cv', number = 5)  #use 5-fold cross validation
inTrain <- createDataPartition(y = data.all$Label, p=0.75, list=FALSE)
training <- data.all[inTrain, ]
testing <- data.all[-inTrain, ]
rfGrid <- expand.grid(mtry = 2^(5:10) )
rffit <- train(Label~., data = training,
method = "rf", trControl = control, tuneGrid = rfGrid
) #parameter tuning
rfGrid <- expand.grid(mtry = 2^(5:10) )
rffit <- train(Label~., data = training,
method = "rf", trControl = control, tuneGrid = rfGrid
) #parameter tuning
r <- sample(1:2000, 2000)
r <- r[1:100]
dat_train<-X[r,]
label_train <- labels[r,1]
data.all <- as.data.frame(cbind(dat_train, label_train))
colnames(data.all)[ncol(data.all)] <- "Label"
data.all$Label <- as.factor(data.all$Label)
control <- trainControl(method = 'cv', number = 5)  #use 5-fold cross validation
inTrain <- createDataPartition(y = data.all$Label, p=0.75, list=FALSE)
training <- data.all[inTrain, ]
testing <- data.all[-inTrain, ]
bestmtry <- tuneRF(y=training$Label, x=train_data[,-5001], stepFactor=1.5, improve=1e-5, ntree=500)
bestmtry <- tuneRF(y=training$Label, x=training[,-5001], stepFactor=1.5, improve=1e-5, ntree=500)
rfGrid <- expand.grid(mtry = 2^(5:10) )
rffit <- train(Label~., data = training,
method = "rf", trControl = control, tuneGrid = rfGrid
) #parameter tuning
rffit
rfGrid <- expand.grid(mtry = 2^(1:8) )
rffit <- train(Label~., data = training,
method = "rf", trControl = control, tuneGrid = rfGrid
) #parameter tuning
svmGrid <- expand.grid(C = c(0.75, 0.9, 1, 1.1, 1.25))
svmfit <- train(Label~., data = training,
method = "svmLinear", trControl = control, tuneGrid = svmGrid, preProc = c("center","scale")
) #parameter tuning
svmfit
svmGrid <- expand.grid(C = c(0.75, 0.9, 1, 1.1, 1.25))
svmfit <- train(Label~., data = training,
method = "svmLinear", trControl = control
) #parameter tuning
svmfit
svmGrid <- expand.grid(C = c(0.001, 1, 10, 100))
svmfit <- train(Label~., data = training,
method = "svmLinear", trControl = control, tuneGrid = svmGrid, preProc = c("center","scale")
) #parameter tuning
svmfit
svmGrid <- expand.grid(sigma= 2^c(-25, -20, -15,-10, -5, 0), C= 2^c(0:5))
svmfit <- train(Label~., data = training,
method = "svmRadial", trControl = control, tuneGrid = svmGrid, preProc = c("center","scale")
) #parameter tuning
svmfit
xgfit <- train(Label~., data = training,
method = "xgboost", trControl = control, tuneGrid = svmGrid
) #parameter tuning
xgfit <- train(Label~., data = training,
method = "xgbLinear", trControl = control, tuneGrid = svmGrid
) #parameter tuning
library("plyr")
library("xgboost")
xgfit <- train(Label~., data = training,
method = "xgbLinear", trControl = control
) #parameter tuning
xgfit
predict(xgfit$finalModel, testing)
predict(xgfit, testing)
sum(predict(xgfit, testing) != testing$Label)
library("ada")
install.packages("ada")
library("ada")
adafit <- train(Label~., data = training,
method = "ada", trControl = control
) #parameter tuning
install.packages("09806-07443-53955-64350-21751-41297")
install.packages("fastAdaboost")
library("fastAdaboost")
adafit <- train(Label~., data = training,
method = "adaboost", trControl = control
) #parameter tuning
xgbfit <- train(Label~., data = training,
method = "xgbLinear", trControl = control
) #parameter tuning
library("caret")
library("gbm")
library("randomForest")
library("plyr")
library("xgboost")
library("fastAdaboost")
library("deepboost")
library("EBImage")
library("e1071")
library("kernlab")
library("OpenImageR")
setwd("~/GitHub/spr2017-proj3-group7/doc/")
source("../lib/feature.R")
source("../lib/train.R")
source("../lib/test.R")
# here replace it with your own path or manually set it in RStudio to where this rmd file is located.
experiment_dir <- "../data/" # This will be modified for different data sets.
img_train_dir <- paste(experiment_dir, "raw_images/", sep="")
img_test_dir <- paste(experiment_dir, "raw_images/", sep="")
load("../output/baseline.RData")
print(baseline$bestTune)
print(mean(baseline$finalModel$train.error))
#load SVM here
load("../output/advanced.RData")
print(advanced$bestTune)
print(advanced$finalModel)
tm_feature_test <- system.time(feature_test <-feature(img_test_dir,export=T))
paste0("../output/HOG.RData")
tm_feature_test <- system.time(feature_test <-feature(img_test_dir,export=T))
#load("../output/HOG.RData")
tm_test_bs <- system.time(pred_test <- test(baseline, feature_test))
tm_test_bs <- system.time(pred_test <- Test(baseline, feature_test))
tm_test_ad <- system.time(pred_test <- Test(advanced, feature_test))
save(pred_test, file="../output/pred_test_ad.RData")
cat("Time for making prediction=", tm_test_ad[1], "s \n")
