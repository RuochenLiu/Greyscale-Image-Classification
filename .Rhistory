"test",
data_name="zip",
export=TRUE))
}
#save(dat_train, file="./output/feature_train.RData")
#save(dat_test, file="./output/feature_test.RData")
source("../lib/train.R")
source("../lib/test.R")
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(length(depth_values), 2))
for(k in 1:length(depth_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat_train, label_train, model_values[k], K)
}
save(err_cv, file="../output/err_cv.RData")
}
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(length(model_values), 2))
for(k in 1:length(depth_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat_train, label_train, model_values[k], K)
}
save(err_cv, file="../output/err_cv.RData")
}
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat_train, label_train, model_values[k], K)
}
save(err_cv, file="../output/err_cv.RData")
}
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
experiment_dir <- "../data/zipcode/" # This will be modified for different data sets.
img_train_dir <- paste(experiment_dir, "train/", sep="")
img_test_dir <- paste(experiment_dir, "test/", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
model_values <- seq(3, 11, 2)
model_labels = paste("GBM with depth =", model_values)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep=""),
header=F)
label_train <- as.numeric(unlist(label_train) == "9")
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir,
"train",
data_name="zip",
export=TRUE))
}
tm_feature_test <- NA
if(run.feature.test){
tm_feature_test <- system.time(dat_test <- feature(img_test_dir,
"test",
data_name="zip",
export=TRUE))
}
#save(dat_train, file="./output/feature_train.RData")
#save(dat_test, file="./output/feature_test.RData")
source("../lib/train.R")
source("../lib/test.R")
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat_train, label_train, model_values[k], K)
}
save(err_cv, file="../output/err_cv.RData")
}
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat_train, label_train, model_values[k], K)
}
save(err_cv, file="../output/err_cv.RData")
}
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat_train, label_train, model_values[k], K)
}
save(err_cv, file="../output/err_cv.RData")
}
if(run.cv){
load("../output/err_cv.RData")
#pdf("../fig/cv_results.pdf", width=7, height=5)
plot(model_values, err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", type="n", ylim=c(0, 0.15))
points(model_values, err_cv[,1], col="blue", pch=16)
lines(model_values, err_cv[,1], col="blue")
arrows(model_values, err_cv[,1]-err_cv[,2],depth_values, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
#dev.off()
}
if(run.cv){
load("../output/err_cv.RData")
#pdf("../fig/cv_results.pdf", width=7, height=5)
plot(model_values, err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", type="n", ylim=c(0, 0.15))
points(model_values, err_cv[,1], col="blue", pch=16)
lines(model_values, err_cv[,1], col="blue")
arrows(model_values, err_cv[,1]-err_cv[,2], model_values, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
#dev.off()
}
if(run.cv){
load("../output/err_cv.RData")
#pdf("../fig/cv_results.pdf", width=7, height=5)
plot(model_values, err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", type="n", ylim=c(0, 0.25))
points(model_values, err_cv[,1], col="blue", pch=16)
lines(model_values, err_cv[,1], col="blue")
arrows(model_values, err_cv[,1]-err_cv[,2], model_values, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
#dev.off()
}
model_best=model_values[1]
if(run.cv){
model_best <- model_values[which.min(err_cv[,1])]
}
par_best <- list(par=model_best)
tm_train=NA
tm_train <- system.time(fit_train <- train(dat_train, label_train, par_best))
View(err_cv)
which.min(err_cv[,1])
tm_train=NA
tm_train <- system.time(fit_train <- train(dat_train, label_train, par_best))
fit_train <- train(dat_train, label_train, par_best)
tm_train=NA
tm_train <- system.time(fit_train <- train(dat_train, label_train, par=par_best))
tm_train=NA
tm_train <- system.time(fit_train <- train(dat_train, label_train, par=par_best))
par_best$par
tm_train=NA
tm_train <- system.time(fit_train <- train(dat_train, label_train, par_best))
source('~/Dropbox/Tian_Teaching/G5243-ADS/0-Projects-startercodes/3-Spring2017/Project3_PoodleKFC/lib/train.R')
tm_train=NA
tm_train <- system.time(fit_train <- train(dat_train, label_train, par_best))
source('~/Dropbox/Tian_Teaching/G5243-ADS/0-Projects-startercodes/3-Spring2017/Project3_PoodleKFC/lib/train.R')
model_best=model_values[1]
if(run.cv){
model_best <- model_values[which.min(err_cv[,1])]
}
par_best <- list(depth=model_best)
tm_train=NA
tm_train <- system.time(fit_train <- train(dat_train, label_train, par_best))
save(fit_train, file="../output/fit_train.RData")
tm_test=NA
if(run.test){
load(file=paste0("../output/feature_", "zip", "_", "test", ".RData"))
load(file="../output/fit_train.RData")
tm_test <- system.time(pred_test <- test(fit_train, dat_test))
save(pred_test, file="../output/pred_test.RData")
}
cat("Time for constructing training features=", tm_feature_train[1], "s \n")
cat("Time for constructing testing features=", tm_feature_test[1], "s \n")
cat("Time for training model=", tm_train[1], "s \n")
cat("Time for making prediction=", tm_test[1], "s \n")
library("caret")
library("gbm")
library("randomForest")
library("plyr")
library("xgboost")
library("fastAdaboost")
X <- read.csv(choose.files())
X <- t(X)
labels <- read.csv(choose.files())
labels <- labels[,1]
dat_train<-X
label_train <- labels
Train <- function(dat_train, label_train){
n <- nrow(dat_train)
r <- sample(1:n, n)
dat_train <- dat_train[r,]
label_train <- label_train[r]
data.all <- as.data.frame(cbind(dat_train, label_train))
colnames(data.all)[ncol(data.all)] <- "Label"
data.all$Label <- as.factor(data.all$Label)
control <- trainControl(method = 'cv', number = 5)  #use 5-fold cross validation
inTrain <- createDataPartition(y = data.all$Label, p=0.75, list=FALSE)
training <- data.all[inTrain, ]
testing <- data.all[-inTrain, ]
# GBM
gbmGrid <- expand.grid(interaction.depth = (1:5) * 2,n.trees = (1:10)*25,shrinkage = .1,
n.minobsinnode = 10)
gbmfit <- train(Label~., data = training,
method = "gbm", trControl = control, verbose = FALSE,
bag.fraction = 0.5, tuneGrid = gbmGrid
) #parameter tuning
err.gbm <- sum(predict(gbmfit, testing) != testing$Label)/nrow(testing)
# Random Forest
rfGrid <- expand.grid(mtry = 2^(5:10) )
rffit <- train(Label~., data = training,
method = "rf", trControl = control, tuneGrid = rfGrid
) #parameter tuning
err.rf <- sum(predict(rffit, testing) != testing$Label)/nrow(testing)
# SVM
svmGrid <- expand.grid(sigma= 2^c(-25, -20, -15,-10, -5, 0), C= 2^c(0:5))
svmfit <- train(Label~., data = training,
method = "svmRadial", trControl = control, tuneGrid = svmGrid, preProc = c("center","scale")
) #parameter tuning
err.svm <- sum(predict(svmfit, testing) != testing$Label)/nrow(testing)
# xgBoost
xgbfit <- train(Label~., data = training,
method = "xgbLinear", trControl = control
) #parameter tuning
err.xgb <- sum(predict(xgbfit, testing) != testing$Label)/nrow(testing)
}
install.packages("caret")
install.packages("xgboost")
install.packages("fastAdaboost")
library("caret")
library("gbm")
library("randomForest")
library("plyr")
library("xgboost")
library("fastAdaboost")
setwd("~/GitHub/spr2017-proj3-group7")
X <- read.csv("../data/sift_features.csv")
getwd()
X <- read.csv("./data/sift_features.csv")
X <- t(X)
labels <- read.csv("./data/labels.csv")
labels <- labels[,1]
dat_train<-X
label_train <- labels
Train <- function(dat_train, label_train){
n <- nrow(dat_train)
r <- sample(1:n, n)
dat_train <- dat_train[r,]
label_train <- label_train[r]
data.all <- as.data.frame(cbind(dat_train, label_train))
colnames(data.all)[ncol(data.all)] <- "Label"
data.all$Label <- as.factor(data.all$Label)
control <- trainControl(method = 'cv', number = 5)  #use 5-fold cross validation
inTrain <- createDataPartition(y = data.all$Label, p=0.75, list=FALSE)
training <- data.all[inTrain, ]
testing <- data.all[-inTrain, ]
# GBM
gbmGrid <- expand.grid(interaction.depth = (1:5) * 2,n.trees = (1:10)*25,shrinkage = .1,
n.minobsinnode = 10)
gbmfit <- train(Label~., data = training,
method = "gbm", trControl = control, verbose = FALSE,
bag.fraction = 0.5, tuneGrid = gbmGrid
) #parameter tuning
err.gbm <- sum(predict(gbmfit, testing) != testing$Label)/nrow(testing)
# Random Forest
rfGrid <- expand.grid(mtry = 2^(5:10) )
rffit <- train(Label~., data = training,
method = "rf", trControl = control, tuneGrid = rfGrid
) #parameter tuning
err.rf <- sum(predict(rffit, testing) != testing$Label)/nrow(testing)
# SVM
svmGrid <- expand.grid(sigma= 2^c(-25, -20, -15,-10, -5, 0), C= 2^c(0:5))
svmfit <- train(Label~., data = training,
method = "svmRadial", trControl = control, tuneGrid = svmGrid, preProc = c("center","scale")
) #parameter tuning
err.svm <- sum(predict(svmfit, testing) != testing$Label)/nrow(testing)
# xgBoost
xgbfit <- train(Label~., data = training,
method = "xgbLinear", trControl = control
) #parameter tuning
err.xgb <- sum(predict(xgbfit, testing) != testing$Label)/nrow(testing)
}
print("gbm error is",err.gbm)
Sys.time()
GBMTrain <- function(dat_train, label_train){
n <- nrow(dat_train)
r <- sample(1:n, n)
dat_train <- dat_train[r,]
label_train <- label_train[r]
data.all <- as.data.frame(cbind(dat_train, label_train))
colnames(data.all)[ncol(data.all)] <- "Label"
data.all$Label <- as.factor(data.all$Label)
control <- trainControl(method = 'cv', number = 5)  #use 5-fold cross validation
inTrain <- createDataPartition(y = data.all$Label, p=0.75, list=FALSE)
training <- data.all[inTrain, ]
testing <- data.all[-inTrain, ]
# GBM
gbmGrid <- expand.grid(interaction.depth = (1:5) * 2,n.trees = (1:10)*25,shrinkage = .1,
n.minobsinnode = 10)
gbmfit <- train(Label~., data = training,
method = "gbm", trControl = control, verbose = FALSE,
bag.fraction = 0.5, tuneGrid = gbmGrid
) #parameter tuning
err.gbm <- sum(predict(gbmfit, testing) != testing$Label)/nrow(testing)
print("gbm error is",err.gbm)
}
RFTrain <- function(dat_train, label_train){
n <- nrow(dat_train)
r <- sample(1:n, n)
dat_train <- dat_train[r,]
label_train <- label_train[r]
data.all <- as.data.frame(cbind(dat_train, label_train))
colnames(data.all)[ncol(data.all)] <- "Label"
data.all$Label <- as.factor(data.all$Label)
control <- trainControl(method = 'cv', number = 5)  #use 5-fold cross validation
inTrain <- createDataPartition(y = data.all$Label, p=0.75, list=FALSE)
training <- data.all[inTrain, ]
testing <- data.all[-inTrain, ]
# Random Forest
rfGrid <- expand.grid(mtry = 2^(5:10) )
rffit <- train(Label~., data = training,
method = "rf", trControl = control, tuneGrid = rfGrid
) #parameter tuning
err.rf <- sum(predict(rffit, testing) != testing$Label)/nrow(testing)
print("rf error is",err.rf)
}
SVMTrain <- function(dat_train, label_train){
n <- nrow(dat_train)
r <- sample(1:n, n)
dat_train <- dat_train[r,]
label_train <- label_train[r]
data.all <- as.data.frame(cbind(dat_train, label_train))
colnames(data.all)[ncol(data.all)] <- "Label"
data.all$Label <- as.factor(data.all$Label)
control <- trainControl(method = 'cv', number = 5)  #use 5-fold cross validation
inTrain <- createDataPartition(y = data.all$Label, p=0.75, list=FALSE)
training <- data.all[inTrain, ]
testing <- data.all[-inTrain, ]
# SVM
svmGrid <- expand.grid(sigma= 2^c(-25, -20, -15,-10, -5, 0), C= 2^c(0:5))
svmfit <- train(Label~., data = training,
method = "svmRadial", trControl = control, tuneGrid = svmGrid, preProc = c("center","scale")
) #parameter tuning
err.svm <- sum(predict(svmfit, testing) != testing$Label)/nrow(testing)
print("svm error is",err.svm)
}
XGBTrain <- function(dat_train, label_train){
n <- nrow(dat_train)
r <- sample(1:n, n)
dat_train <- dat_train[r,]
label_train <- label_train[r]
data.all <- as.data.frame(cbind(dat_train, label_train))
colnames(data.all)[ncol(data.all)] <- "Label"
data.all$Label <- as.factor(data.all$Label)
control <- trainControl(method = 'cv', number = 5)  #use 5-fold cross validation
inTrain <- createDataPartition(y = data.all$Label, p=0.75, list=FALSE)
training <- data.all[inTrain, ]
testing <- data.all[-inTrain, ]
# xgBoost
xgbfit <- train(Label~., data = training,
method = "xgbLinear", trControl = control
) #parameter tuning
err.xgb <- sum(predict(xgbfit, testing) != testing$Label)/nrow(testing)
print("xgb error is",err.xgb)
}
t1<-Sys.time()
GBMTrain(X,labels)
t2<-Sys.time()
print("GBM time is",difftime(t1,t2))
library(mlbench)
library(e1071)
data(BreastCancer)
#summary(BreastCancer)
L<-length(BreastCancer[,1])
BreastCancer<-na.omit(BreastCancer)
tcon<-tune.control(sampling="cross",cross=5)
library(mlbench)
library(e1071)
data(BreastCancer)
#summary(BreastCancer)
L<-length(BreastCancer[,1])
na_idx<-rowSums(is.na(BreastCancer))>0
BreastCancer<-na.omit(BreastCancer)
tcon<-tune.control(sampling="cross",cross=5)
t=0.7
train_idx<-sample(L,floor(L*t))
train_data<-BreastCancer[train_idx,2:11]
test_data<-BreastCancer[-train_idx,2:11]
bsvm <- best.svm(Class~.,data=train_data,kernel="radial",
gamma = 2^(-2:2), cost = 2^(0:4),
tunecontrol=tcon)
svm.pred<-predict(bsvm,test_data[,-10])
er<-sum(svm.pred!=test_data[,10])/length(test_data[,10])
er
print("error rate is ", er*100, "%.")
print(paste("error rate is ", er*100, "%."))
print(paste("error rate is ", round(er*100,2), "%."))
error<-rep(0,50)
for (n in 1:50)
{
set.seed(1)
t=runif(1,0,1)
train_idx<-sample(L,floor(L*t))
train_data<-BreastCancer[train_idx,2:11]
test_data<-BreastCancer[-train_idx,2:11]
bsvm <- best.svm(Class~.,data=train_data,kernel="radial",
gamma = 2^(-2:2), cost = 2^(0:4),
tunecontrol=tcon)
svm.pred<-predict(bsvm,test_data[,-10])
error[n]<-sum(svm.pred!=test_data[,10])/length(test_data[,10])
}
print(paste("mean of error rate is ",round(mean(error)*100,2), "%."))
print(paste("standard error is",round(sd(error),4)))
t=0.7
train_idx<-sample(L,floor(L*t))
train_data<-BreastCancer[train_idx,2:11]
test_data<-BreastCancer[-train_idx,2:11]
bsvm <- best.svm(Class~.,data=train_data,kernel="radial",
gamma = 2^(-2:2), cost = 2^(0:4),
tunecontrol=tcon)
svm.pred<-predict(bsvm,test_data[,-10])
er<-sum(svm.pred!=test_data[,10])/length(test_data[,10])
print(paste("error rate is ", round(er*100,2), "%."))
error<-rep(0,50)
for (n in 1:50)
{
t=runif(1,0,1)
train_idx<-sample(L,floor(L*t))
train_data<-BreastCancer[train_idx,2:11]
test_data<-BreastCancer[-train_idx,2:11]
bsvm <- best.svm(Class~.,data=train_data,kernel="radial",
gamma = 2^(-2:2), cost = 2^(0:4),
tunecontrol=tcon)
svm.pred<-predict(bsvm,test_data[,-10])
error[n]<-sum(svm.pred!=test_data[,10])/length(test_data[,10])
}
error<-rep(0,50)
for (n in 1:50)
{
t=0.7
train_idx<-sample(L,floor(L*t))
train_data<-BreastCancer[train_idx,2:11]
test_data<-BreastCancer[-train_idx,2:11]
bsvm <- best.svm(Class~.,data=train_data,kernel="radial",
gamma = 2^(-2:2), cost = 2^(0:4),
tunecontrol=tcon)
svm.pred<-predict(bsvm,test_data[,-10])
error[n]<-sum(svm.pred!=test_data[,10])/length(test_data[,10])
}
print(paste("mean of error rate is ",round(mean(error)*100,2), "%."))
print(paste("standard error is",round(sd(error),4)))
ts<-(10:19)*0.05
N<-50
M<-length(tvals)
ts<-(10:19)*0.05
N<-50
M<-length(ts)
errors<-matrix(0,nrow=N,ncol=M)
for (m in 1:M)
{
for (n in 1:N)
{
train_idx<-sample(L,floor(L*ts[m]))
train_data<-BreastCancer[train_idx,2:11]
test_data<-BreastCancer[-train_idx,2:11]
bsvm <- best.svm(Class~.,data=train_data,kernel="radial",
gamma = 2^(-2:2), cost = 2^(0:4),
tunecontrol=tcon)
svm.pred<-predict(bsvm,test_data[,-10])
errors[n,m]<-sum(svm.pred!=test_data[,10])/length(test_data[,10])
}
}
er_sd<-apply(erors,4,sd)
er_sd<-apply(errors,4,sd)
er_sd<-apply(errors,2,sd)
er_m<-apply(errors,2,mean)
plot(tvals,er_m,ylim=c(0.017,0.035),xlab="t",ylab="error rate")
plot(ts,er_m,ylim=c(0.017,0.035),xlab="t",ylab="error rate")
points(ts,er_m-er_sd*1.96/sqrt(50),col=2)
points(ts,er_m+er_sd*1.96/sqrt(50),col=3)
boxplot(er,names=tvals)
boxplot(errors,names=ts)
title(xlab="t",ylab="error rate")
error_m<-apply(errors,2,mean)
error_sd<-apply(errors,2,sd)
plot(ts,error_m,ylim=c(0.017,0.035),xlab="t",ylab="error rate")
summary(error_m)
plot(ts,error_m,ylim=c(0.024,0.03),xlab="t",ylab="mean error rate")
points(ts,error_m-error_sd*1.96/sqrt(50),col=2)
plot(ts,error_m,ylim=c(0.024,0.03),xlab="t",ylab="mean error rate")
points(ts,error_m-error_sd*1.96/sqrt(50),col=2)
points(ts,error_m+error_sd*1.96/sqrt(50),col=3)
plot(ts,error_m,ylim=c(0.015,0.035),xlab="t",ylab="mean error rate")
points(ts,error_m-error_sd*1.96/sqrt(50),col=2)
points(ts,error_m+error_sd*1.96/sqrt(50),col=3)
summary(error_m)
plot(ts,error_m,ylim=c(0.015,0.035),xlab="t",ylab="mean error rate")
points(ts,error_m-error_sd*1.96/sqrt(50),col=2)
points(ts,error_m+error_sd*1.96/sqrt(50),col=3)
boxplot(errors,names=ts)
title(xlab="t",ylab="error rate")
